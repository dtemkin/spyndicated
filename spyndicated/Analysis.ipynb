{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Blog Entries:  485\n",
      "Number of News Entries:  1308\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def read_data(datafile=os.path.join(os.getcwd(), '.data', 'master.json')):\n",
    "    with open(datafile, mode='r') as f:\n",
    "        lines = [json.loads(l) for l in f.readlines()]\n",
    "        return lines\n",
    "\n",
    "data = read_data()\n",
    "for x in data:\n",
    "    if x['is_blog'] is True:\n",
    "        x.update({\"is_blog\": 1})\n",
    "    else:\n",
    "        x.update({\"is_blog\": 0})\n",
    "blog_entries = [d for d in data if d['is_blog'] == 1]\n",
    "news_entries = [d for d in data if d['is_blog'] == 0]\n",
    "print(\"Number of Blog Entries: \", len(blog_entries))\n",
    "print(\"Number of News Entries: \", len(news_entries))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'file:///home/cmustard/Projects/spyndicated/spyndicated/temp-plot.html'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly import graph_objs as go\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "kwds = []\n",
    "[kwds.extend(d['kwds']) for d in data]\n",
    "kwd_counts = dict(Counter(kwds))\n",
    "pltdata = [go.Bar(x=[k for k in kwd_counts.keys()], y=[v for v in kwd_counts.values()])]\n",
    "plot(pltdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim import corpora, models\n",
    "allids = set(range(len(data)))\n",
    "\n",
    "training_sample_ids = set(np.random.choice(range(len(data)), 600))\n",
    "testing_sample_ids = set(np.random.choice([i for i in allids-training_sample_ids], 300))\n",
    "training_entries = [data[i] for i in training_sample_ids]\n",
    "testing_entries = [data[j] for j in testing_sample_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "testing_kwds = [j['kwds'] for j in testing_entries]\n",
    "training_kwds = [i['kwds'] for i in training_entries]\n",
    "# print(testing_kwds[:5])\n",
    "# print(training_kwds[:5])\n",
    "d = corpora.Dictionary(training_kwds)\n",
    "testing_corpus_bows = [d.doc2bow(j) for j in testing_kwds]\n",
    "training_corpus_bows = [d.doc2bow(i) for i in training_kwds]\n",
    "lda = models.ldamodel.LdaModel(corpus=training_corpus_bows, num_topics=60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n"
     ]
    }
   ],
   "source": [
    "xt = lda.show_topic(0)\n",
    "xt[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 0.046789072), ('to', 0.037078563), ('of', 0.022894038), ('and', 0.019087298), (' ', 0.018943932), ('in', 0.01805378), ('that', 0.012170301), ('for', 0.010497646), ('is', 0.008926169), ('with', 0.008617311)]\n",
      "[('the', 0.021527715), ('and', 0.010586378), ('to', 0.010497752), ('learning', 0.009277596), ('machine', 0.00927698), ('in', 0.008134774), ('you', 0.0067978585), ('transportation', 0.006549915), ('commerce', 0.0064039775), ('with', 0.0053081596)]\n",
      "[('the', 0.041114416), ('to', 0.019302355), (' ', 0.015952364), ('and', 0.013408236), ('as', 0.011857941), ('on', 0.011206151), ('of', 0.011138467), ('in', 0.011125654), ('for', 0.009067276), ('pyeongchang', 0.008593416)]\n",
      "[(' ', 0.056847308), ('the', 0.031264044), ('and', 0.02310892), ('in', 0.018392801), ('for', 0.013221009), ('at', 0.012601764), ('is', 0.009805018), ('of', 0.0072937696), ('to', 0.007167674), ('   ', 0.0066799065)]\n",
      "[('to', 0.042998634), ('the', 0.040379044), ('of', 0.017852118), (' ', 0.015242027), ('that', 0.01494789), ('in', 0.013673326), ('is', 0.0135479625), ('and', 0.012027894), ('for', 0.009033579), ('data', 0.008598269)]\n",
      "[('the', 0.02253385), (' ', 0.022123223), ('and', 0.019103112), ('in', 0.016563514), ('to', 0.015547127), ('of', 0.01391339), ('for', 0.013431773), ('   ', 0.01270461), ('is', 0.0072640004), ('that', 0.005794361)]\n",
      "[('the', 0.038632963), ('to', 0.027593857), ('and', 0.0215754), (' ', 0.020402865), ('in', 0.017427446), ('of', 0.014467987), ('that', 0.009737827), ('for', 0.009385851), ('on', 0.009241112), ('it', 0.008506785)]\n",
      "[('the', 0.0468194), ('to', 0.03877611), ('of', 0.029621352), ('in', 0.024044009), ('and', 0.018221023), (' ', 0.011477595), ('for', 0.00919347), ('is', 0.008222051), ('on', 0.00808743), ('at', 0.0073063215)]\n",
      "[('the', 0.065829016), (' ', 0.031561315), ('of', 0.0312781), ('to', 0.027273064), ('and', 0.023909606), ('in', 0.01387243), ('is', 0.013724154), ('that', 0.011784216), ('on', 0.011314937), ('for', 0.01083907)]\n",
      "[('the', 0.020915857), (' ', 0.018116562), ('   ', 0.015221308), ('of', 0.014372861), ('to', 0.012575812), ('and', 0.011009585), ('is', 0.007896328), ('in', 0.005545936), ('for', 0.00489365), ('that', 0.0035588667)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    print([(d.id2token[int(x[0])], x[1]) for x in lda.show_topic(i)])\n",
    "#testing_tops = [lda.get_document_topics(jbow) for jbow in testing_corpus_bows]\n",
    "\n",
    "#training_tops = [lda.get_document_topics(ibow) for ibow in training_corpus_bows]\n",
    "\n",
    "# for i in range(len(training_sample_ids)):\n",
    "#    training_entries[i].update({\"topics\": training_tops[i]})    \n",
    "# for j in range(len(testing_sample_ids)):\n",
    "#    testing_entries[j].update({\"topics\": testing_tops[j]})\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blogkwds = []\n",
    "blogtags = []\n",
    "blogtopics = []\n",
    "newskwds = []\n",
    "newstags = []\n",
    "newstopics = []\n",
    "\n",
    "for j in range(len(testing_entries)):\n",
    "    ent = testing_entries[j]\n",
    "    for tag in ent['tags']:\n",
    "        tt = []\n",
    "        if type(tag) is list:\n",
    "            tt.append(tag[0])\n",
    "        else:\n",
    "            tt.append(tag)\n",
    "        if len(tt) > 0:\n",
    "            ent.update({\"tags\": tt})\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    if ent['is_blog'] == 1:\n",
    "        blogkwds.extend([i for i in ent['kwds']])\n",
    "        blogtags.extend([i.split(\",\")[0] for i in ent['tags']])\n",
    "        blogtopics.extend([i[0] for i in ent['topics']])\n",
    "    else:\n",
    "        newskwds.extend([i for i in ent['kwds']])\n",
    "        newstags.extend([i for i in ent['tags']])\n",
    "        newstopics.extend([i[0] for i in ent['topics']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kwd_layout = go.Layout(barmode='overlay', title='Keyword Probabilities by Source Type')\n",
    "BlogKeywords = go.Histogram(x=blogkwds, name='Blog Keywords', histnorm='probability', opacity=0.75)\n",
    "NewsKeywords = go.Histogram(x=newskwds, name='News Keywords', histnorm='probability', opacity=0.75)\n",
    "kwd_traces = [BlogKeywords, NewsKeywords]\n",
    "kwd_fig = go.Figure(data=kwd_traces, layout=kwd_layout)\n",
    "iplot(kwd_fig)\n",
    "\n",
    "tag_layout = go.Layout(barmode='overlay', title='Tag Frequencies by Source Type')\n",
    "BlogTags = go.Histogram(x=blogtags, name='Blog Tags', opacity=0.75)\n",
    "NewsTags = go.Histogram(x=newstags, name='News Tags', opacity=0.75)\n",
    "tag_traces = [BlogTags, NewsTags]\n",
    "tag_fig = go.Figure(data=tag_traces, layout=tag_layout)\n",
    "iplot(tag_fig)\n",
    "\n",
    "topics_layout = go.Layout(barmode='overlay', title='Topic Probabilities by Source Type')\n",
    "BlogTopics = go.Histogram(x=blogtopics, name='Blog Topics', histnorm='probability', opacity=0.75)\n",
    "NewsTopics = go.Histogram(x=newstopics, name='News Topics', histnorm='probability', opacity=0.75)\n",
    "topics_traces = [BlogTopics, NewsTopics]\n",
    "topics_fig = go.Figure(data=topics_traces, layout=topics_layout)\n",
    "iplot(topics_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
